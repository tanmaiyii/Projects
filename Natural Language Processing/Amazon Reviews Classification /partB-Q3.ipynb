{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART B\n",
    "\n",
    "### Q3. Sentiment Analysis \n",
    "In this section, the sentiment of the reviews has been looked at. To build the sentiment classifer, the deception classifer has been retained although modified.The review rating has been set as the sentiment gold standard. Reviews that got 1-2 stars are classified as negative reviews and the reviews that got 4-5 stars are positive. The rating has been used as the feature label. Previously in the Deception Classifier, the real or fake labels have been used. Whereas here, positive or negative rating has been set as the label. The rating is the 3rd column in the dataset. That is line[2] when setting it in the defined python function ParseReview. Accordingly, the load data function has been modified to append the new positive and negative lists. neg_data and pos_data have been initialised as empty lists when loading the dataset and calling the loadData function. Another aspect that was considered is the size of the positive and negative reviews. There are 16183 positive reviews whereas only 2949 negative reviews. As such, when testing the data, before splitting the data into train and test, the rawData function has been set to only take 2500 each of positive and negative reviews so that there is a balanced dataset. It can be seen that for the sentiment classifer the accuracy improves, using only the standard features that is only ID and the review text. The accuracy scores have been reported in the report. Also, additional features have been added to the default features of the Review Text and ID. Each additional feature has been replaced in the LoadData and ParseReview function. The features have been updated to the dictionary in the splitData function. For example first product title was added, and then replaced by verified purchase in the LoadData, ParseReview and SplitData function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "# coding: utf-8\n",
    "import csv  \n",
    "import unicodecsv   # csv reader\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from random import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from a file and append it to the rawData\n",
    "def loadData(path, Text=None):\n",
    "    with open(path, 'rb') as f:\n",
    "        reader = unicodecsv.reader(f, encoding='utf-8', delimiter='\\t')\n",
    "        next(reader)\n",
    "        for line in reader:\n",
    "            (Id, Text, Label, Category) = parseReview(line)\n",
    "            if Label == \"negative\":\n",
    "                neg_data.append((Id, Text, Label, Category))\n",
    "            elif Label == \"positive\":\n",
    "                pos_data.append((Id, Text, Label, Category))\n",
    "#             rawData is now a combination of pos_data and neg_dataâ€º\n",
    "#             rawData.append((Id, Text, Label))\n",
    "            preprocessedData.append((Id, preProcess(Text), Label, Category))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(percentage):\n",
    "    dataSamples = len(rawData)\n",
    "    halfOfData = int(len(rawData)/2)\n",
    "    trainingSamples = int((percentage*dataSamples)/2)\n",
    "    for (_, Text, Label, Category) in rawData[:trainingSamples] + rawData[halfOfData:halfOfData+trainingSamples]:\n",
    "        d = (toFeatureVector(preProcess(Text)))\n",
    "        d.update({\"Product_Category\": Category})\n",
    "        trainData.append((d,Label))\n",
    "#         trainData.append((toFeatureVector(preProcess(Text)),Label))\n",
    "    for (_, Text, Label, Category) in rawData[trainingSamples:halfOfData] + rawData[halfOfData+trainingSamples:]:\n",
    "        testData.append((toFeatureVector(preProcess(Text)),Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive and negative reviews\n",
    "Pos = 0\n",
    "Neg = 0\n",
    "three = 0\n",
    "# N, P, T = 0, 0, 0\n",
    "\n",
    "# DOC_ID\tLABEL\tRATING\tVERIFIED_PURCHASE\tPRODUCT_CATEGORY\tPRODUCT_ID\tPRODUCT_TITLE\tREVIEW_TITLE\tREVIEW_TE\n",
    "# Convert line from input file into an id/text/label tuple\n",
    "def parseReview(reviewLine):\n",
    "    # Use rating as a label and selecting positive and negative reviews\n",
    "    Id = reviewLine[0]\n",
    "    Text = reviewLine[8]\n",
    "    Prod_Title = reviewLine[6]\n",
    "    Review_Title = reviewLine[7]\n",
    "    Verified = reviewLine[3]\n",
    "    Category = reviewLine[4]\n",
    "    Label = reviewLine[2]\n",
    "    if int(reviewLine[2]) < 3:\n",
    "        Label = \"negative\"\n",
    "        global Neg\n",
    "        Neg += 1\n",
    "    elif int(reviewLine[2]) >= 4:\n",
    "        Label = \"positive\"\n",
    "        global Pos\n",
    "        Pos += 1\n",
    "    else:\n",
    "        Label = \"none\"\n",
    "        global three\n",
    "        three += 1\n",
    "\n",
    "\n",
    "    return (Id, Text, Label, Category)\n",
    "\n",
    "# TEXT PREPROCESSING\n",
    "\n",
    "def preProcess(text):\n",
    "    #normalisation and tokenising \n",
    "    no_symbols = re.sub(r'[^\\w]', ' ', text.lower())\n",
    "    tokens = no_symbols.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTION 2 ##\n",
    "# ################\n",
    "featureDict = {} # A global dictionary of features\n",
    "\n",
    "def toFeatureVector(words):\n",
    "    v = {}\n",
    "    for w in words:\n",
    "        try:\n",
    "            i = featureDict[w]\n",
    "        except KeyError:\n",
    "            i = len(featureDict) + 1\n",
    "            featureDict[w] = i\n",
    "        try:\n",
    "            v[w] += (1.0/len(words))\n",
    "        except KeyError:\n",
    "            v[w] = (1.0/len(words))\n",
    "    return v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16183\n",
      "2949\n",
      "1868\n",
      "21000\n"
     ]
    }
   ],
   "source": [
    "print(Pos)\n",
    "print(Neg)\n",
    "print(three)\n",
    "sum = 16183+2949+1868\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "## QUESTION 3 ##\n",
    "################\n",
    "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
    "def trainClassifier(trainData):\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
    "    return SklearnClassifier(pipeline).train(trainData)\n",
    "\n",
    "\n",
    "myTestData = []\n",
    "myTrainData = []\n",
    "\n",
    "def crossValidate(dataset, folds):\n",
    "    cv_results = []\n",
    "    accuracy = []\n",
    "    shuffle(dataset)\n",
    "    foldSize = int(len(dataset)/folds)\n",
    "    for i in range(0,len(dataset),foldSize):\n",
    "        # insert code here that trains and tests on the 10 folds of data in the dataset\n",
    "        print (\"fold start %d foldSize %d\" % (i, foldSize))\n",
    "        myTestData = dataset[i:i+foldSize]\n",
    "        myTrainData = dataset[0:i] + dataset[i+foldSize:]\n",
    "        classifier = trainClassifier(myTrainData)\n",
    "        y_pred = predictLabels(myTestData, classifier)\n",
    "#         review,label = zip(*myTestData)\n",
    "#         y_true = label\n",
    "        y_true = [x[1] for x in myTestData]\n",
    "#         y_true = classifier.classify(map(lambda x: x[1], myTestData))\n",
    "        cv_results.append(precision_recall_fscore_support(y_true, y_pred, average='weighted'))\n",
    "        accuracy.append(accuracy_score(y_true, y_pred))\n",
    "        \n",
    "#Calclualte avergae of values over the 10-fold runs\n",
    "    cv_results = np.asarray(cv_results)\n",
    "    cv_results = [np.mean(cv_results[:,0]), np.mean(cv_results[:,1]), np.mean(cv_results[:,2])]\n",
    "    \n",
    "    accuracy = np.asarray(accuracy)\n",
    "    accuracy = np.mean(accuracy)\n",
    "    cv_results.append(accuracy)\n",
    "    \n",
    "    return cv_results\n",
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "\n",
    "\n",
    "def predictLabels(reviewSamples, classifier):\n",
    "    return classifier.classify_many(map(lambda t: t[0], reviewSamples))\n",
    "\n",
    "def predictLabel(reviewSample, classifier):\n",
    "    return classifier.classify(toFeatureVector(preProcess(reviewSample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now 0 rawData, 0 trainData, 0 testData\n",
      "Preparing the dataset...\n",
      "Now 0 rawData, 0 trainData, 0 testData\n",
      "Preparing training and test data...\n",
      "Now 5000 rawData, 4000 trainData, 1000 testData\n",
      "Training Samples: \n",
      "4000\n",
      "Features: \n",
      "14888\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "# loading reviews\n",
    "rawData = []          # the filtered data from the dataset file (should be 21000 samples)\n",
    "preprocessedData = [] # the preprocessed reviews (just to see how your preprocessing is doing)\n",
    "trainData = []        # the training data as a percentage of the total dataset (currently 80%, or 16800 samples)\n",
    "testData = []  # the test data as a percentage of the total dataset (currently 20%, or 4200 samples)\n",
    "pos_data = []\n",
    "neg_data = []\n",
    "# the output classes\n",
    "# fakeLabel = 'fake'\n",
    "# realLabel = 'real'\n",
    "\n",
    "# references to the data files\n",
    "reviewPath = 'amazon_reviews.txt'\n",
    "\n",
    "## Do the actual stuff\n",
    "# We parse the dataset and put it in a raw data list\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
    "      \"Preparing the dataset...\",sep='\\n')\n",
    "loadData(reviewPath)\n",
    "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
    "      \"Preparing training and test data...\",sep='\\n')\n",
    "\n",
    "# selecting rawData to be of a balanced dataset\n",
    "rawData = pos_data[:2500] + neg_data[:2500]\n",
    "\n",
    "splitData(0.8)\n",
    "# We print the number of training samples and the number of features\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
    "      \"Training Samples: \", len(trainData), \"Features: \", len(featureDict), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold start 0 foldSize 400\n",
      "Training Classifier...\n",
      "fold start 400 foldSize 400\n",
      "Training Classifier...\n",
      "fold start 800 foldSize 400\n",
      "Training Classifier...\n",
      "fold start 1200 foldSize 400\n",
      "Training Classifier...\n",
      "fold start 1600 foldSize 400\n",
      "Training Classifier...\n",
      "fold start 2000 foldSize 400\n",
      "Training Classifier...\n",
      "fold start 2400 foldSize 400\n",
      "Training Classifier...\n",
      "fold start 2800 foldSize 400\n",
      "Training Classifier...\n",
      "fold start 3200 foldSize 400\n",
      "Training Classifier...\n",
      "fold start 3600 foldSize 400\n",
      "Training Classifier...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7789407899415657, 0.7780000000000001, 0.777974589526049, 0.778]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidate(trainData, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
