{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                      NLP Assignment - 1\n",
    "\n",
    "\n",
    "## Part A - Deception Detection\n",
    "\n",
    "\n",
    "### 5. Adding additional features to improve performance\n",
    "\n",
    "Three addtional features have been added namely Rating, Product_category and Verified_purchase. Each one of them have been tested separately and have also been added together. All three of these datatypes have been added and the performance is tested. The additional features have been added to the parseReview and have been updated in the dictionary in the loadData function itself using the update method of the dictionary.The standard preprocessing function is used. The following code has been implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv  \n",
    "import unicodecsv   # csv reader\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from random import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "# libraries for: regular expressions, file I/O\n",
    "import sys\n",
    "from sklearn.metrics import * # to report on precision and recall\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from textstat.textstat import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data from a file and append it to the rawData\n",
    "def loadData(path, Text=None):\n",
    "    with open(path, 'rb') as f:\n",
    "        reader = unicodecsv.reader(f, encoding='utf-8', delimiter='\\t')\n",
    "        next(reader)\n",
    "        for line in reader: #Add the new features\n",
    "            (Id, Text, Label, Rating, Verified, Category) = parseReview(line)\n",
    "            rawData.append((Id, Text, Label, Rating, Verified, Category))\n",
    "            preprocessedData.append((Id, preProcess(Text), Label, Rating, Verified, Category))  \n",
    "\n",
    "def splitData(percentage):\n",
    "    dataSamples = len(rawData)\n",
    "    halfOfData = int(len(rawData)/2)\n",
    "    trainingSamples = int((percentage*dataSamples)/2)\n",
    "    for (_, Text, Label, Rating, Verified, Category) in rawData[:trainingSamples] + rawData[halfOfData:halfOfData+trainingSamples]:\n",
    "        # Update the dictionary\n",
    "        d = (toFeatureVector(preProcess(Text)))\n",
    "        d.update({\"Rating\": Rating, \"Verfied_purchase\": Verified, \"Product_category\": Category})\n",
    "        trainData.append((d,Label))\n",
    "    for (_, Text, Label, Rating, Verified, Category) in rawData[trainingSamples:halfOfData] + rawData[halfOfData+trainingSamples:]:\n",
    "        testData.append((toFeatureVector(preProcess(Text)),Label))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "## QUESTION 5##\n",
    "################\n",
    "def parseReview(reviewLine):\n",
    "    # Should return a triple of an integer, a string containing the review, and a string indicating the label\n",
    "#     L = []\n",
    "    Id = (reviewLine[0])\n",
    "    Text = (reviewLine[8])\n",
    "    Label = (reviewLine[1])\n",
    "    Rating = (reviewLine[2])\n",
    "    Verified = (reviewLine[3])\n",
    "    Category = (reviewLine[4])\n",
    "    return (Id, Text, Label, Rating, Verified, Category)\n",
    "\n",
    "# TEXT PREPROCESSING\n",
    "\n",
    "def preProcess(text):\n",
    "    #normalisation and tokenising \n",
    "    no_symbols = re.sub(r'[^\\w]', ' ', text.lower())\n",
    "    tokens = no_symbols.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. toFeatureVector\n",
    "The next step is to implement the toFeatureVector function. Given a preprocessed review (that is, a list of tokens), this function will return a dictionary that has its keys as the tokens and values as the weight of those tokens in the preprocessed reviews. The weight has been given as the number of occurences of a token divided by the total token occurences in the preprocessed review. The global featureDict, which is the dictionary that keeps track of all the tokens in the whole review dataset has been incrementally built up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "## QUESTION 2 ##\n",
    "################\n",
    "featureDict = {} # A global dictionary of features\n",
    "def toFeatureVector(words):\n",
    "    v = {}\n",
    "    for w in words:\n",
    "        try:\n",
    "            i = featureDict[w]\n",
    "        except KeyError:\n",
    "            i = len(featureDict) + 1\n",
    "            featureDict[w] = i\n",
    "        try:\n",
    "            v[w] += (1.0/len(words))\n",
    "        except KeyError:\n",
    "            v[w] = (1.0/len(words))\n",
    "    return v\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  crossValidate function\n",
    "The crossValidate function has been completed to do a 10-fold cross validation. The precision_recall_fscore_support function has been used to compute the precision, recall, f1 score.The f1-score gives you the harmonic mean of precision and recall. The scores corresponding to every class will tell you the accuracy of the classifier in classifying the data points in that particular class compared to all other classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "## QUESTION 3 ##\n",
    "################\n",
    "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
    "def trainClassifier(trainData):\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
    "    return SklearnClassifier(pipeline).train(trainData)\n",
    "\n",
    "\n",
    "myTestData = []\n",
    "myTrainData = []\n",
    "\n",
    "    \n",
    "def crossValidate(dataset, folds):\n",
    "    cv_results = []\n",
    "    accuracy = []\n",
    "    shuffle(dataset)\n",
    "    foldSize = int(len(dataset)/folds)\n",
    "    for i in range(0,len(dataset),foldSize):\n",
    "        # insert code here that trains and tests on the 10 folds of data in the dataset\n",
    "        print (\"fold start %d foldSize %d\" % (i, foldSize))\n",
    "        myTestData = dataset[i:i+foldSize]\n",
    "        myTrainData = dataset[0:i] + dataset[i+foldSize:]\n",
    "        classifier = trainClassifier(myTrainData)\n",
    "        y_pred = predictLabels(myTestData, classifier)\n",
    "#         review,label = zip(*myTestData)\n",
    "#         y_true = label\n",
    "        y_true = [x[1] for x in myTestData]\n",
    "#         y_true = classifier.classify(map(lambda x: x[1], myTestData))\n",
    "        cv_results.append(precision_recall_fscore_support(y_true, y_pred, average='weighted'))\n",
    "        accuracy.append(accuracy_score(y_true, y_pred))\n",
    "        \n",
    "#Calclualte avergae of values over the 10-fold runs\n",
    "    cv_results = np.asarray(cv_results)\n",
    "    cv_results = [np.mean(cv_results[:,0]), np.mean(cv_results[:,1]), np.mean(cv_results[:,2])]\n",
    "    \n",
    "    accuracy = np.asarray(accuracy)\n",
    "    accuracy = np.mean(accuracy)\n",
    "    cv_results.append(accuracy)\n",
    "    \n",
    "    return cv_results\n",
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "\n",
    "\n",
    "def predictLabels(reviewSamples, classifier):\n",
    "    return classifier.classify_many(map(lambda t: t[0], reviewSamples))\n",
    "\n",
    "def predictLabel(reviewSample, classifier):\n",
    "    return classifier.classify(toFeatureVector(preProcess(reviewSample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing the above functions, the loadData function is called to load the data. Consequently the functions defined above have been called. The corresponding accuracy scores have been calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now 0 rawData, 0 trainData, 0 testData\n",
      "Preparing the dataset...\n",
      "Now 21000 rawData, 0 trainData, 0 testData\n",
      "Preparing training and test data...\n",
      "Now 21000 rawData, 16800 trainData, 4200 testData\n",
      "Training Samples: \n",
      "16800\n",
      "Features: \n",
      "34913\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "# loading reviews\n",
    "rawData = []          # the filtered data from the dataset file (should be 21000 samples)\n",
    "preprocessedData = [] # the preprocessed reviews (just to see how your preprocessing is doing)\n",
    "trainData = []        # the training data as a percentage of the total dataset (currently 80%, or 16800 samples)\n",
    "testData = []         # the test data as a percentage of the total dataset (currently 20%, or 4200 samples)\n",
    "\n",
    "# the output classes\n",
    "fakeLabel = 'fake'\n",
    "realLabel = 'real'\n",
    "\n",
    "# references to the data files\n",
    "reviewPath = 'amazon_reviews.txt'\n",
    "\n",
    "## Do the actual stuff\n",
    "# We parse the dataset and put it in a raw data list\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
    "      \"Preparing the dataset...\",sep='\\n')\n",
    "loadData(reviewPath)\n",
    "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
    "      \"Preparing training and test data...\",sep='\\n')\n",
    "splitData(0.8)\n",
    "# We print the number of training samples and the number of features\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
    "      \"Training Samples: \", len(trainData), \"Features: \", len(featureDict), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold start 0 foldSize 1680\n",
      "Training Classifier...\n",
      "fold start 1680 foldSize 1680\n",
      "Training Classifier...\n",
      "fold start 3360 foldSize 1680\n",
      "Training Classifier...\n",
      "fold start 5040 foldSize 1680\n",
      "Training Classifier...\n",
      "fold start 6720 foldSize 1680\n",
      "Training Classifier...\n",
      "fold start 8400 foldSize 1680\n",
      "Training Classifier...\n",
      "fold start 10080 foldSize 1680\n",
      "Training Classifier...\n",
      "fold start 11760 foldSize 1680\n",
      "Training Classifier...\n",
      "fold start 13440 foldSize 1680\n",
      "Training Classifier...\n",
      "fold start 15120 foldSize 1680\n",
      "Training Classifier...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7886369657711093,\n",
       " 0.7873809523809524,\n",
       " 0.7871645716981799,\n",
       " 0.7873809523809523]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidate(trainData, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
