{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B Q2\n",
    "\n",
    "### Linguistic traits of the fake and real reviews\n",
    "In this part, some of the linguistic and stylistic traits of the reviews are examined and the two classes are compared. The classes have been separated into fake and real classes and various aspects have been analysed. The average length of the text, the average word length, stop words, capital words, punctuation, Flesch Kinkaid reading level have been analysed. Also, counted the number of time the product title appears in the review text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "# coding: utf-8\n",
    "import csv  \n",
    "import unicodecsv   # csv reader\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from random import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from textstat.textstat import textstat\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction import stop_words\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sb\n",
    "from string import ascii_lowercase, ascii_uppercase\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk import trigrams\n",
    "###Does one class contain more stopwords than the others?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from a file and append it to the rawData\n",
    "def loadData(path, Text=None):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        next(reader)\n",
    "        \n",
    "        for line in reader:\n",
    "            (Label, Text, prod_title) = parseReview(line)\n",
    "            rawData.append((Label, Text, prod_title))\n",
    "            preprocessedData.append((Label,preProcess(Text), prod_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseReview(reviewLine):\n",
    "    Label = str(reviewLine[1])\n",
    "    if Label == '__label1__':\n",
    "        Label = 'fake'\n",
    "    else:\n",
    "        Label = 'real'\n",
    "        \n",
    "    rating = str(reviewLine[2])\n",
    "    verified = str(reviewLine[3])\n",
    "    prod_category = str(reviewLine[4])\n",
    "    Text = str(reviewLine[8])\n",
    "    prod_title = (reviewLine[6])\n",
    "\n",
    "    return (Label, Text, prod_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(text):\n",
    "    #normalisation and tokenising \n",
    "    no_symbols = re.sub(r'[^\\w]', ' ', text.lower())\n",
    "    tokens = no_symbols.split()\n",
    "    # Should return a list of tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = []\n",
    "preprocessedData = []\n",
    "reviewPath = 'amazon_reviews.txt'\n",
    "loadData(reviewPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(preprocessedData[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fake', 'When least you think so, this product will save the day. Just keep it around just in case you need it for something.', 'Targus PAUK10U Ultra Mini USB Keypad, Black')]\n"
     ]
    }
   ],
   "source": [
    "print(rawData[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeClass = []\n",
    "realClass = []\n",
    "\n",
    "def labelClass(text):\n",
    "\n",
    "    for line in text:\n",
    "        if line[0] == 'fake':\n",
    "            fakeClass.append(line)\n",
    "        else:\n",
    "            realClass.append(line)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelClass(preprocessedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFakeReviews = pd.DataFrame(fakeClass)\n",
    "dfRealReviews = pd.DataFrame(realClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fake', ['when', 'least', 'you', 'think', 'so', 'this', 'product', 'will', 'save', 'the', 'day', 'just', 'keep', 'it', 'around', 'just', 'in', 'case', 'you', 'need', 'it', 'for', 'something'], 'Targus PAUK10U Ultra Mini USB Keypad, Black')\n"
     ]
    }
   ],
   "source": [
    "print (fakeClass[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average length in fake reviews is: 61 \n",
      "The average length in real reviews is: 81\n"
     ]
    }
   ],
   "source": [
    "#how long are the reviews for each class?\n",
    "###On average, how long are the reviews for each class?\n",
    "def AvLength(text):\n",
    "    textlength = []\n",
    "    for i in text[1]:\n",
    "        len(i)\n",
    "        textlength.append(len(i))\n",
    "        \n",
    "    return np.mean(textlength)\n",
    "\n",
    "print (\"The average length in fake reviews is: %d \" % AvLength(dfFakeReviews))\n",
    "\n",
    "print (\"The average length in real reviews is: %d\" % AvLength(dfRealReviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preData=[]\n",
    "for (Label,Text, prod_title) in rawData:\n",
    "    preData.append((Label,preProcess(Text),prod_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average word length per class\n",
    "#divide fake or real\n",
    "fake_words = []\n",
    "real_words = []\n",
    "\n",
    "for i in range(len(preData)):\n",
    "    if (rawData[i][0] == 'fake'):\n",
    "        fake_words.append(preData[i][1])\n",
    "    else:\n",
    "        real_words.append(preData[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Counting word real and word fake\n",
    "word_len_fake = []\n",
    "word_len_real = []\n",
    "\n",
    "for i in range(len(real_words)):\n",
    "    for j in range(len(real_words[i])):\n",
    "        word_len_real.append(len(real_words[i][j]))\n",
    "        \n",
    "for i in range(len(fake_words)):\n",
    "    for j in range(len(fake_words[i])):\n",
    "        word_len_fake.append(len(fake_words[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0762300770383675\n",
      "4.057513688906916\n"
     ]
    }
   ],
   "source": [
    "## Average word length per class\n",
    "print(np.average(word_len_real))\n",
    "print(np.average(word_len_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More complex measures - Flesch Kinkaid Readability Test\n",
    "str_fake = []\n",
    "str_real= []\n",
    "\n",
    "fki_fake = []\n",
    "fki_real = []\n",
    "\n",
    "for i in range(len(rawData)):\n",
    "    if (rawData[i][0] == 'fake'):\n",
    "        str_fake.append(rawData[i][1])\n",
    "    else:\n",
    "        str_real.append(rawData[i][1])\n",
    "        \n",
    "for t in range(len(str_fake)):\n",
    "    fki_fake.append(textstat.flesch_reading_ease(str_fake[t]))\n",
    "\n",
    "for t in range(len(str_real)):\n",
    "    fki_real.append(textstat.flesch_reading_ease(str_real[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fake average is:  79.75902761904763\n",
      "The real average is:  79.029706666667\n"
     ]
    }
   ],
   "source": [
    "fake_average = sum(fki_fake)/len(fki_fake)\n",
    "real_average = sum(fki_real)/len(fki_real)\n",
    "\n",
    "print(\"The fake average is: \", fake_average)\n",
    "print(\"The real average is: \", real_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words in fake labels:  641030\n",
      "stop words in fake labels 330168\n",
      "total words in real labels:  857365\n",
      "stop words in real labels 428835\n",
      "% of stopwords fake: 51.50585776016723\n",
      "% of stopwords real: 50.01778705685444\n"
     ]
    }
   ],
   "source": [
    "###Does one class contain more stopwords than the others?\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "fake_stopwords = []\n",
    "real_stopwords = []\n",
    "real_total =[]\n",
    "fake_total = []\n",
    "\n",
    "#Total words in real label\n",
    "for i in range(len(real_words)):\n",
    "    for w in real_words[i]:\n",
    "        real_total.append(w)\n",
    "        \n",
    "#Total words in fake label\n",
    "for i in range(len(fake_words)):\n",
    "    for w in fake_words[i]:\n",
    "        fake_total.append(w)\n",
    "\n",
    "#stopwords in real label\n",
    "for i in range(len(real_words)):\n",
    "    for w in real_words[i]:\n",
    "        if w in stopWords:\n",
    "            real_stopwords.append(w)\n",
    "\n",
    "#stopwords in fake label\n",
    "for i in range(len(fake_words)):\n",
    "    for w in fake_words[i]:\n",
    "        if w in stopWords:\n",
    "            fake_stopwords.append(w)\n",
    "\n",
    "print(\"total words in fake labels: \" , len(fake_total))\n",
    "print(\"stop words in fake labels\" , len(fake_stopwords))\n",
    "\n",
    "print(\"total words in real labels: \" ,len(real_total))\n",
    "print(\"stop words in real labels\" , len(real_stopwords))\n",
    "\n",
    "stopword_per_fake = len(fake_stopwords)/len(fake_total)*100\n",
    "\n",
    "stopword_per_real = len(real_stopwords)/len(real_total)*100\n",
    "\n",
    "print(\"% of stopwords fake:\" , stopword_per_fake)\n",
    "print(\"% of stopwords real:\" , stopword_per_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###The use of punctuation \n",
    "\n",
    "import string\n",
    "\n",
    "count = lambda l1, l2 : len(list(filter(lambda c: c in l2, l1)))\n",
    "sum_fake_punct = 0\n",
    "sum_real_punct = 0\n",
    "\n",
    "for i in range(len(str_fake)):\n",
    "    for w in str_fake[i]:\n",
    "        punct_fake = count(w, string.punctuation)\n",
    "        sum_fake_punct += punct_fake\n",
    "\n",
    "for i in range(len(str_real)):\n",
    "    for w in str_real[i]:\n",
    "        punct_real = count(w, string.punctuation)\n",
    "        sum_real_punct += punct_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punctuation in fake label: 106917\n",
      "punctuation in real label:  163501\n"
     ]
    }
   ],
   "source": [
    "print(\"punctuation in fake label:\" , sum_fake_punct)\n",
    "print(\"punctuation in real label: \", sum_real_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of capital words in fake and real classes\n",
    "fakeClassUpper = []\n",
    "realClassUpper = []\n",
    "\n",
    "def labelClass(text):\n",
    "\n",
    "    for line in text:\n",
    "        if line[0] == \"fake\":\n",
    "            fakeClassUpper.append(line)\n",
    "        else:\n",
    "            realClassUpper.append(line)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelClass(rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capital Words in real class: 53874\n"
     ]
    }
   ],
   "source": [
    "# Counting the no. of Capital words in the fake reviews\n",
    "labelClass(rawData)\n",
    "count=0\n",
    "for record in fakeClassUpper:\n",
    "    for word in record[1].split(\" \"):\n",
    "        if word.isupper():\n",
    "            count += 1   \n",
    "                \n",
    "print(\"Capital Words in real class: \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capital Words in real class: 99039\n"
     ]
    }
   ],
   "source": [
    "# Counting the no. of capital words in real reviews\n",
    "\n",
    "labelClass(rawData)\n",
    "count=0\n",
    "for record in realClassUpper:\n",
    "    for word in record[1].split(\" \"):\n",
    "        if word.isupper():\n",
    "            count += 1   \n",
    "                \n",
    "print(\"Capital Words in real class: \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of times the product title appears in Reviews\n",
    "tokenData=[]\n",
    "for (Label,Text, prod_title) in rawData:\n",
    "    tokenData.append((Label,Text, preProcess(prod_title)))\n",
    "title_fake = 0\n",
    "title_real= 0\n",
    "for i in range(len(tokenData)):\n",
    "    if (rawData[i][0] == 'fake'):\n",
    "        if tokenData[i][2][0] in tokenData[i][1]:\n",
    "            title_fake+=1\n",
    "    else:\n",
    "        if tokenData[i][2][0] in tokenData[i][1]:\n",
    "            title_real+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake: 1065\n",
      "Real: 924\n"
     ]
    }
   ],
   "source": [
    "print(\"Fake: \" + str(title_fake))\n",
    "print(\"Real: \"+ str(title_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
