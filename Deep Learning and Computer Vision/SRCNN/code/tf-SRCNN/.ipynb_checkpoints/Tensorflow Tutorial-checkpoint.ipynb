{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib as mp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import math\n",
    "import skimage\n",
    "from weights_viz import put_kernels_on_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tanmaiyiirao/Desktop/CW1_for_students/CW1_Handout_Template_code/tf-SRCNN\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import pdb\n",
    "import skimage\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(path, is_grayscale=True):\n",
    "  \"\"\"\n",
    "  Read image using its path.\n",
    "  Default value is gray-scale, and image is read by YCbCr format as the paper said.\n",
    "  \"\"\"\n",
    "  if is_grayscale:\n",
    "    return scipy.misc.imread(path, flatten=True, mode='YCbCr').astype(np.float)\n",
    "  else:\n",
    "    return scipy.misc.imread(path, mode='YCbCr').astype(np.float)\n",
    "\n",
    "def modcrop(image, scale=3):\n",
    "  \"\"\"\n",
    "  To scale down and up the original image, first thing to do is to have no remainder while scaling operation.\n",
    "\n",
    "  We need to find modulo of height (and width) and scale factor.\n",
    "  Then, subtract the modulo from height (and width) of original image size.\n",
    "  There would be no remainder even after scaling operation.\n",
    "  \"\"\"\n",
    "  if len(image.shape) == 3:\n",
    "    h, w, _ = image.shape\n",
    "    h = h - np.mod(h, scale)\n",
    "    w = w - np.mod(w, scale)\n",
    "    image = image[0:h, 0:w, :]\n",
    "  else:\n",
    "    h, w = image.shape\n",
    "    h = h - np.mod(h, scale)\n",
    "    w = w - np.mod(w, scale)\n",
    "    image = image[0:h, 0:w]\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(path, scale=3):\n",
    "    \"\"\"\n",
    "    Preprocess single image file\n",
    "    (1) Read original image as YCbCr format (and grayscale as default)\n",
    "    (2) Normalize\n",
    "    (3) Apply image file with bicubic interpolation\n",
    "    Args:\n",
    "    path: file path of desired file\n",
    "    input_: image applied bicubic interpolation (low-resolution)\n",
    "    label_: image with original resolution (high-resolution)\"\"\"\n",
    "    image = imread(path, is_grayscale=True)\n",
    "    label_ = modcrop(image, scale)\n",
    "    return image\n",
    "\n",
    "# import matplotlib.cm as cm # \n",
    "ground_truth_image = preprocess('./image/butterfly_GT.bmp')\n",
    "scipy.misc.imsave('ground_truth.jpg', ground_truth_image)\n",
    "# plt.imshow(blurred_image, cmap = cm.Greys_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(path, is_grayscale=True):\n",
    "  \"\"\"\n",
    "  Read image using its path.\n",
    "  Default value is gray-scale, and image is read by YCbCr format as the paper said.\n",
    "  \"\"\"\n",
    "  if is_grayscale:\n",
    "    return scipy.misc.imread(path, flatten=True, mode='YCbCr').astype(np.float)\n",
    "  else:\n",
    "    return scipy.misc.imread(path, mode='YCbCr').astype(np.float)\n",
    "\n",
    "def modcrop(image, scale=3):\n",
    "  \"\"\"\n",
    "  To scale down and up the original image, first thing to do is to have no remainder while scaling operation.\n",
    "\n",
    "  We need to find modulo of height (and width) and scale factor.\n",
    "  Then, subtract the modulo from height (and width) of original image size.\n",
    "  There would be no remainder even after scaling operation.\n",
    "  \"\"\"\n",
    "  if len(image.shape) == 3:\n",
    "    h, w, _ = image.shape\n",
    "    h = h - np.mod(h, scale)\n",
    "    w = w - np.mod(w, scale)\n",
    "    image = image[0:h, 0:w, :]\n",
    "  else:\n",
    "    h, w = image.shape\n",
    "    h = h - np.mod(h, scale)\n",
    "    w = w - np.mod(w, scale)\n",
    "    image = image[0:h, 0:w]\n",
    "  return image\n",
    "\n",
    "\n",
    "def preprocess(path, scale=3):\n",
    "  \"\"\"\n",
    "  Preprocess single image file\n",
    "    (1) Read original image as YCbCr format (and grayscale as default)\n",
    "    (2) Normalize\n",
    "    (3) Apply image file with bicubic interpolation\n",
    "  Args:\n",
    "    path: file path of desired file\n",
    "    input_: image applied bicubic interpolation (low-resolution)\n",
    "    label_: image with original resolution (high-resolution)\n",
    "  \"\"\"\n",
    "  image = imread(path, is_grayscale=True)\n",
    "  label_ = modcrop(image, scale)\n",
    "\n",
    "  # Must be normalized\n",
    "  image = image / 255.\n",
    "  label_ = label_ / 255.\n",
    "\n",
    "  input_ = scipy.ndimage.interpolation.zoom(label_, (1./scale), prefilter=False)\n",
    "#   scipy.misc.imsave('image/3.jpg', input_)\n",
    "#   pdb.set_trace()\n",
    "  input_ = scipy.ndimage.interpolation.zoom(input_, (scale/1.), prefilter=False)\n",
    "#   scipy.misc.imsave('image*3.jpg', input_)\n",
    "  print (input_.shape)\n",
    "  return input_, label_\n",
    "# print (input_.shape) #(1, 255, 255, 1)\n",
    "# blurred_image, groudtruth_image = preprocess('./image/butterfly_GT.bmp')\n",
    "\n",
    "\n",
    "# pdb.set_trace()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set the image hyper parameters\n",
    "\"\"\"\n",
    "c_dim = 1\n",
    "input_size = 255\n",
    "\n",
    "\"\"\"Define the model weights and biases\n",
    "\"\"\"\n",
    "\n",
    "# define the placeholders for inputs and outputs\n",
    "inputs = tf.placeholder(tf.float32, [None, input_size, input_size, c_dim], name='inputs')\n",
    "\n",
    "## ------ Add your code here: set the weight of three conv layers\n",
    "# replace '0' with your hyper parameter numbers\n",
    "# conv1 layer with biases: 64 filters with size 9 x 9\n",
    "# conv2 layer with biases and relu: 32 filters with size 1 x 1\n",
    "# conv3 layer with biases and NO relu: 1 filter with size 5 x 5\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.random_normal([9, 9, 1, 64], stddev=1e-3), name='w1'),\n",
    "    'w2': tf.Variable(tf.random_normal([1, 1, 64, 32], stddev=1e-3), name='w2'),\n",
    "    'w3': tf.Variable(tf.random_normal([5, 5, 32, 1], stddev=1e-3), name='w3')\n",
    "    }\n",
    "#\n",
    "biases = {\n",
    "      'b1': tf.Variable(tf.zeros([64]), name='b1'),\n",
    "      'b2': tf.Variable(tf.zeros([32]), name='b2'),\n",
    "      'b3': tf.Variable(tf.zeros([1]), name='b3')\n",
    "    }\n",
    "#\n",
    "# \"\"\"Define the model layers with three convolutional layers\n",
    "# \"\"\"\n",
    "# ## ------ Add your code here: to compute feature maps of input low-resolution images\n",
    "# # replace 'None' with your layers: use the tf.nn.conv2d() and tf.nn.relu()\n",
    "# # conv1 layer with biases and relu : 64 filters with size 9 x 9\n",
    "#\n",
    "conv1 = tf.nn.relu(tf.nn.conv2d(inputs, weights['w1'], strides=[1,1,1,1], padding='VALID') + biases['b1'])\n",
    "##------ Add your code here: to compute non-linear mapping\n",
    "# # conv2 layer with biases and relu: 32 filters with size 1 x 1\n",
    "#\n",
    "conv2 = tf.nn.relu(tf.nn.conv2d(conv1, weights['w2'], strides=[1,1,1,1], padding='VALID') + biases['b2'])\n",
    "# ##------ Add your code here: compute the reconstruction of high-resolution image\n",
    "# # conv3 layer with biases and NO relu: 1 filter with size 5 x 5\n",
    "conv3 = tf.nn.conv2d(conv2, weights['w3'], strides=[1,1,1,1], padding='VALID') + biases['b3']\n",
    "#\n",
    "\n",
    "# pdb.set_trace()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./model/model.npy'\n",
    "model = np.load(model_path, encoding = 'latin1').item() #latin1\n",
    "\n",
    "# pdb.set_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 9, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "weight_w1 = model['w1']\n",
    "print (weight_w1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "w1_1 = scipy.misc.imsave('w1_1.jpg', weight_w1[:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1\n",
      "w2\n",
      "w3\n",
      "b1\n",
      "b2\n",
      "b3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for key in weights.keys():\n",
    "    print(key)\n",
    "    sess.run(weights[key].assign(model[key]))\n",
    "\n",
    "for key in biases.keys():\n",
    "    print(key)\n",
    "    sess.run(biases[key].assign(model[key]))\n",
    "\n",
    "# pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 255)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Read the test image\n",
    "\"\"\"\n",
    "blurred_image, groundtruth_image = preprocess('./image/butterfly_GT.bmp')\n",
    "\"\"\"Run the model and get the SR image\n",
    "\"\"\"\n",
    "# transform the input to 4-D tensor\n",
    "input_ = np.expand_dims(np.expand_dims(blurred_image, axis =0), axis=-1)\n",
    "#\n",
    "# # run the session\n",
    "# # here you can also run to get feature map like 'conv1' and 'conv2'\n",
    "output_ = sess.run(conv3, feed_dict={inputs: input_})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 255)\n",
      "(255, 255)\n",
      "(243, 243, 1)\n"
     ]
    }
   ],
   "source": [
    "print(blurred_image.shape)\n",
    "print(groundtruth_image.shape)\n",
    "print(output_[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "scipy.misc.imsave('ground_truth123.jpg', groundtruth_image)\n",
    "scipy.misc.imsave('BI123.jpg', blurred_image)\n",
    "scipy.misc.imsave('SR123.jpg', output_[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.453967418499577\n",
      "21.77124830643141\n"
     ]
    }
   ],
   "source": [
    "##------ Add your code here: save the blurred and SR images and compute the psnr\n",
    "# hints: use the 'scipy.misc.imsave()'  and ' skimage.meause.compare_psnr()'\n",
    "# skimage.measure.compare_psnr(BI, SR, data_range=None, dynamic_range=None) # compare with ground_truth image\n",
    "\n",
    "# ## Computing psnr between ground_truth and BI and ground_truth and SR\n",
    "\n",
    "# # from skimage.transform import resize\n",
    "# # from skimage import measure\n",
    "# ground_truth = scipy.misc.imread('GT11.jpg')\n",
    "# gt_1 = ground_truth[6:249,6:249]\n",
    "# gt_2 = ground_truth[0:243,0:243]\n",
    "# # gt_1 = (ground_truth, (255, 255), mode='reflect').astype(np.uint8)\n",
    "# # gt_2 = resize(ground_truth, (243, 243), mode='reflect').astype(np.uint8)\n",
    "\n",
    "# #  Decode a JPG image and resize it to 299 by 299 using default method.\n",
    "# # gt_1 = tf.image.decode_jpeg('g_t.jpg')\n",
    "# # resized_1 = tf.image.resize_images(gt_1, [255, 255])\n",
    "# # final1 = np.array(resized_1)\n",
    "\n",
    "# # gt_2 = tf.image.decode_jpeg('g_t.jpg')\n",
    "# # resized_2 = tf.image.resize_images(gt_2, [243, 243])\n",
    "# # final2 = np.array(resized_2)\n",
    "\n",
    "# bicubic = scipy.misc.imread('BI.jpg')\n",
    "# b1_1 = bicubic[6:249,6:249]\n",
    "\n",
    "# super_res = scipy.misc.imread('SR.jpg')\n",
    "\n",
    "# print (bicubic.shape)\n",
    "\n",
    "# print (ground_truth.shape)\n",
    "\n",
    "# print (super_res.shape)\n",
    "\n",
    "# psnr1 = skimage.measure.compare_psnr(gt_1, bicubic, data_range=None, dynamic_range=None) # BI psnr\n",
    "\n",
    "# psnr2 = skimage.measure.compare_psnr(gt_2, super_res, data_range=None, dynamic_range=None) # SR psnr\n",
    "\n",
    "# print (psnr1)\n",
    "\n",
    "# print (psnr2)\n",
    "\n",
    "gt_2 = groundtruth_image[6:249,6:249]\n",
    "# gt_1 = (ground_truth, (255, 255), mode='reflect').astype(np.uint8)\n",
    "\n",
    "b1_1 = blurred_image[6:249,6:249]\n",
    "\n",
    "\n",
    "# sr_1 = output_.astype(np.float64)\n",
    "sr_1 = output_[0,:,:,0].astype(np.float64)\n",
    "\n",
    "# super_res = scipy.misc.imread('SR_final.jpg')\n",
    "\n",
    "# print (bicubic.shape)\n",
    "\n",
    "# print (ground_truth.shape)\n",
    "\n",
    "# print (super_res.shape)\n",
    "\n",
    "# psnr1 = skimage.measure.compare_psnr(gt_2, b1_1, data_range=None, dynamic_range=None) # BI psnr\n",
    "\n",
    "# psnr2 = skimage.measure.compare_psnr(gt_2, sr_1, data_range=None, dynamic_range=None) # SR psnr\n",
    "\n",
    "psnr1 = skimage.measure.compare_psnr(gt_2, b1_1) # BI psnr\n",
    "psnr2 = skimage.measure.compare_psnr(gt_2, sr_1) # SR psnr\n",
    "\n",
    "\n",
    "\n",
    "print (psnr1)\n",
    "\n",
    "print (psnr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print (gt_1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(input_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ([0]) # 0 row, 0 col - [42 30 22]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 255, 255, 1)\n"
     ]
    }
   ],
   "source": [
    "print(output_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
