{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import pdb\n",
    "import skimage\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(path, is_grayscale=True):\n",
    "  \"\"\"\n",
    "  Read image using its path.\n",
    "  Default value is gray-scale, and image is read by YCbCr format as the paper said.\n",
    "  \"\"\"\n",
    "  if is_grayscale:\n",
    "    return scipy.misc.imread(path, flatten=True, mode='YCbCr').astype(np.float)\n",
    "  else:\n",
    "    return scipy.misc.imread(path, mode='YCbCr').astype(np.float)\n",
    "\n",
    "def modcrop(image, scale=3):\n",
    "  \"\"\"\n",
    "  To scale down and up the original image, first thing to do is to have no remainder while scaling operation.\n",
    "\n",
    "  We need to find modulo of height (and width) and scale factor.\n",
    "  Then, subtract the modulo from height (and width) of original image size.\n",
    "  There would be no remainder even after scaling operation.\n",
    "  \"\"\"\n",
    "  if len(image.shape) == 3:\n",
    "    h, w, _ = image.shape\n",
    "    h = h - np.mod(h, scale)\n",
    "    w = w - np.mod(w, scale)\n",
    "    image = image[0:h, 0:w, :]\n",
    "  else:\n",
    "    h, w = image.shape\n",
    "    h = h - np.mod(h, scale)\n",
    "    w = w - np.mod(w, scale)\n",
    "    image = image[0:h, 0:w]\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path, scale=3):\n",
    "  \"\"\"\n",
    "  Preprocess single image file\n",
    "    (1) Read original image as YCbCr format (and grayscale as default)\n",
    "    (2) Normalize\n",
    "    (3) Apply image file with bicubic interpolation\n",
    "  Args:\n",
    "    path: file path of desired file\n",
    "    input_: image applied bicubic interpolation (low-resolution)\n",
    "    label_: image with original resolution (high-resolution)\n",
    "  \"\"\"\n",
    "  image = imread(path, is_grayscale=True)\n",
    "  label_ = modcrop(image, scale)\n",
    "\n",
    "  # Must be normalized\n",
    "  image = image / 255.\n",
    "  label_ = label_ / 255.\n",
    "\n",
    "  input_ = scipy.ndimage.interpolation.zoom(label_, (1./scale), prefilter=False)\n",
    "  \n",
    "  input_ = scipy.ndimage.interpolation.zoom(input_, (scale/1.), prefilter=False)\n",
    " \n",
    "\n",
    "  return input_, label_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (ground_truth_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set the image hyper parameters\n",
    "\"\"\"\n",
    "c_dim = 1\n",
    "input_size = 255\n",
    "\n",
    "\"\"\"Define the model weights and biases\n",
    "\"\"\"\n",
    "\n",
    "# define the placeholders for inputs and outputs\n",
    "inputs = tf.placeholder(tf.float32, [None, input_size, input_size, c_dim], name='inputs')\n",
    "\n",
    "## ------ Add your code here: set the weight of three conv layers\n",
    "# replace '0' with your hyper parameter numbers\n",
    "# conv1 layer with biases: 64 filters with size 9 x 9\n",
    "# conv2 layer with biases and relu: 32 filters with size 1 x 1\n",
    "# conv3 layer with biases and NO relu: 1 filter with size 5 x 5\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.random_normal([9, 9, 1, 64], stddev=1e-3), name='w1'),\n",
    "    'w2': tf.Variable(tf.random_normal([1, 1, 64, 32], stddev=1e-3), name='w2'),\n",
    "    'w3': tf.Variable(tf.random_normal([5, 5, 32, 1], stddev=1e-3), name='w3')\n",
    "    }\n",
    "#\n",
    "biases = {\n",
    "      'b1': tf.Variable(tf.zeros([64]), name='b1'),\n",
    "      'b2': tf.Variable(tf.zeros([32]), name='b2'),\n",
    "      'b3': tf.Variable(tf.zeros([1]), name='b3')\n",
    "    }\n",
    "#\n",
    "# \"\"\"Define the model layers with three convolutional layers\n",
    "# \"\"\"\n",
    "# ## ------ Add your code here: to compute feature maps of input low-resolution images\n",
    "# # replace 'None' with your layers: use the tf.nn.conv2d() and tf.nn.relu()\n",
    "# # conv1 layer with biases and relu : 64 filters with size 9 x 9\n",
    "#\n",
    "conv1 = tf.nn.relu(tf.nn.conv2d(inputs, weights['w1'], strides=[1,1,1,1], padding='VALID') + biases['b1'])\n",
    "##------ Add your code here: to compute non-linear mapping\n",
    "# # conv2 layer with biases and relu: 32 filters with size 1 x 1\n",
    "#\n",
    "conv2 = tf.nn.relu(tf.nn.conv2d(conv1, weights['w2'], strides=[1,1,1,1], padding='VALID') + biases['b2'])\n",
    "# ##------ Add your code here: compute the reconstruction of high-resolution image\n",
    "# # conv3 layer with biases and NO relu: 1 filter with size 5 x 5\n",
    "conv3 = tf.nn.conv2d(conv2, weights['w3'], strides=[1,1,1,1], padding='VALID') + biases['b3']\n",
    "\n",
    "\n",
    "# pdb.set_trace()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./model/model.npy'\n",
    "model = np.load(model_path, encoding = 'latin1').item() #latin1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_w1 = model['w1']\n",
    "print (weight_w1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(weight_w1[:,:,0,0], interpolation = None, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "scipy.misc.imsave('w1_1.jpg', weight_w1[:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8)) #width, height in inches of the window size\n",
    "\n",
    "for i in range(64): #number of filters\n",
    "    sub = fig.add_subplot(8,8, i +1)\n",
    "    sub.imshow(weight_w1[:,:,0,i], interpolation = None, cmap = 'gray')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "fig.savefig('weight_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_w2 = model['w2']\n",
    "print (weight_w2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8)) #width, height in inches of the window size\n",
    "\n",
    "for i in range(32): #number of filters\n",
    "    sub = fig.add_subplot(4,8, i +1)\n",
    "    sub.imshow(weight_w2[:,:,0,i], interpolation = None, cmap = 'gray')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "fig.savefig('weight_2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_w3 = model['w3']\n",
    "print (weight_w3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(weight_w3[:,:,0,0], interpolation = None, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "scipy.misc.imsave('weight_3.jpg', weight_w3[:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key in weights.keys():\n",
    "    print(key)\n",
    "    sess.run(weights[key].assign(model[key]))\n",
    "\n",
    "for key in biases.keys():\n",
    "    print(key)\n",
    "    sess.run(biases[key].assign(model[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Read the test image\n",
    "\"\"\"\n",
    "blurred_image, groundtruth_image = preprocess('./image/butterfly_GT.bmp')\n",
    "\"\"\"Run the model and get the SR image\n",
    "\"\"\"\n",
    "# transform the input to 4-D tensor\n",
    "input_ = np.expand_dims(np.expand_dims(blurred_image, axis =0), axis=-1)\n",
    "\n",
    "# # run the session\n",
    "# # here you can also run to get feature map like 'conv1' and 'conv2'\n",
    "output_ = sess.run(conv3, feed_dict={inputs: input_})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_.shape)\n",
    "print(blurred_image.shape)\n",
    "print(output_.shape)\n",
    "print(groundtruth_image.shape)\n",
    "print (output_.shape)\n",
    "\n",
    "print (type(input_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##------ Add your code here: save the blurred and SR images and compute the psnr\n",
    "# hints: use the 'scipy.misc.imsave()'  and ' skimage.meause.compare_psnr()'\n",
    "scipy.misc.imsave('Blurred.jpg', blurred_image)\n",
    "scipy.misc.imsave('SR.jpg', output_[0,:,:,0])\n",
    "scipy.misc.imsave('ground_truth.jpg',groundtruth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_2 = groundtruth_image[6:249,6:249] #convert the ground_truth to same size as SR image by cropping the edges\n",
    "\n",
    "b1_1 = blurred_image[6:249,6:249]  #convert the blurred to same size as SR and ground_truth image by cropping the edges\n",
    "\n",
    "sr_1 = output_[0,:,:,0].astype(np.float64) #convert the datatype of SR to same as blurred and groundtruth\n",
    "\n",
    "#compute PSNR for Blurred Image with ground_truth image\n",
    "\n",
    "psnr1 = skimage.measure.compare_psnr(gt_2, b1_1, data_range=None, dynamic_range=None) # BI psnr\n",
    "\n",
    "#compute PSNR for SR Image with ground_truth image\n",
    "\n",
    "psnr2 = skimage.measure.compare_psnr(gt_2, sr_1, data_range=None, dynamic_range=None) # SR psnr\n",
    "\n",
    "print (\"Blurred(BI) psnr: \"+ str(psnr1))\n",
    "\n",
    "print (\"SR psnr: \"+ str(psnr2))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
